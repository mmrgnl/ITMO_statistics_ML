{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDjH5VgLMPCa"
   },
   "source": [
    "# Задача 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8T7M9eQMRRn"
   },
   "source": [
    "Пусть $X_1, X_2, \\ldots, X_n$ — выборка из экспоненциального распределения с параметром $\\lambda$. Найти оценку максимального правдоподобия параметра $\\lambda$, сравнить ее с байесовской оценкой (MAP и математическое ожидание апостреорного распределения), подобрав сопряженное распределение. Сравнить полученные байесовские оценки с оценкой MLE. Найти предсказательное распределение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение задачи 1\n",
    "\n",
    "### 1. Оценка максимального правдоподобия (MLE)\n",
    "\n",
    "Плотность экспоненциального распределения:\n",
    "$$f(x|\\lambda) = \\lambda e^{-\\lambda x}, \\quad x \\geq 0$$\n",
    "\n",
    "Функция правдоподобия для выборки $X_1, X_2, \\ldots, X_n$:\n",
    "$$L(\\lambda) = \\prod_{i=1}^n \\lambda e^{-\\lambda X_i} = \\lambda^n e^{-\\lambda \\sum_{i=1}^n X_i}$$\n",
    "\n",
    "Логарифмическая функция правдоподобия:\n",
    "$$\\ell(\\lambda) = n\\ln(\\lambda) - \\lambda \\sum_{i=1}^n X_i$$\n",
    "\n",
    "Находим производную и приравниваем к нулю:\n",
    "$$\\frac{d\\ell}{d\\lambda} = \\frac{n}{\\lambda} - \\sum_{i=1}^n X_i = 0$$\n",
    "\n",
    "Отсюда получаем оценку максимального правдоподобия:\n",
    "$$\\hat{\\lambda}_{MLE} = \\frac{n}{\\sum_{i=1}^n X_i} = \\frac{1}{\\bar{X}}$$\n",
    "\n",
    "где $\\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i$ — выборочное среднее.\n",
    "\n",
    "### 2. Байесовский вывод с сопряженным априорным распределением\n",
    "\n",
    "**Сопряженное распределение:** Гамма-распределение\n",
    "\n",
    "Априорное распределение параметра $\\lambda$:\n",
    "$$\\pi(\\lambda) = \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} \\lambda^{\\alpha-1} e^{-\\beta\\lambda}, \\quad \\lambda > 0$$\n",
    "\n",
    "где $\\alpha > 0$ и $\\beta > 0$ — параметры априорного распределения (гиперпараметры).\n",
    "\n",
    "**Апостериорное распределение:**\n",
    "\n",
    "Используя формулу Байеса:\n",
    "$$\\pi(\\lambda|X) \\propto L(\\lambda) \\cdot \\pi(\\lambda) = \\lambda^n e^{-\\lambda \\sum X_i} \\cdot \\lambda^{\\alpha-1} e^{-\\beta\\lambda}$$\n",
    "\n",
    "$$\\pi(\\lambda|X) \\propto \\lambda^{n+\\alpha-1} e^{-\\lambda(\\sum X_i + \\beta)}$$\n",
    "\n",
    "Это форма гамма-распределения! Следовательно:\n",
    "$$\\lambda|X \\sim \\text{Gamma}(\\alpha + n, \\beta + \\sum_{i=1}^n X_i)$$\n",
    "\n",
    "**MAP оценка (максимум апостериорной вероятности):**\n",
    "\n",
    "Для гамма-распределения мода находится в точке $\\frac{\\alpha-1}{\\beta}$ (при $\\alpha > 1$).\n",
    "\n",
    "Для апостериорного распределения:\n",
    "$$\\hat{\\lambda}_{MAP} = \\frac{\\alpha + n - 1}{\\beta + \\sum_{i=1}^n X_i}$$\n",
    "\n",
    "**Математическое ожидание апостериорного распределения:**\n",
    "\n",
    "Для гамма-распределения $E[\\lambda] = \\frac{\\alpha}{\\beta}$, поэтому:\n",
    "$$\\hat{\\lambda}_{E[\\lambda|X]} = E[\\lambda|X] = \\frac{\\alpha + n}{\\beta + \\sum_{i=1}^n X_i}$$\n",
    "\n",
    "### 3. Сравнение оценок\n",
    "\n",
    "- **MLE:** $\\hat{\\lambda}_{MLE} = \\frac{n}{\\sum X_i} = \\frac{1}{\\bar{X}}$\n",
    "- **MAP:** $\\hat{\\lambda}_{MAP} = \\frac{\\alpha + n - 1}{\\beta + \\sum X_i}$\n",
    "- **Posterior Mean:** $\\hat{\\lambda}_{E[\\lambda|X]} = \\frac{\\alpha + n}{\\beta + \\sum X_i}$\n",
    "\n",
    "**Наблюдения:**\n",
    "- При больших $n$ все три оценки сходятся к $\\frac{1}{\\bar{X}}$\n",
    "- MAP и Posterior Mean учитывают априорную информацию через параметры $\\alpha$ и $\\beta$\n",
    "- При $\\alpha = 1, \\beta \\to 0$ (неинформативный априор) байесовские оценки приближаются к MLE\n",
    "- Posterior Mean всегда больше MAP (при $\\alpha + n > 1$)\n",
    "\n",
    "### 4. Предсказательное распределение\n",
    "\n",
    "Предсказательное распределение для нового наблюдения $X_{n+1}$:\n",
    "$$f(x_{n+1}|X) = \\int_0^{\\infty} f(x_{n+1}|\\lambda) \\pi(\\lambda|X) d\\lambda$$\n",
    "\n",
    "Подставляя:\n",
    "$$f(x_{n+1}|X) = \\int_0^{\\infty} \\lambda e^{-\\lambda x_{n+1}} \\cdot \\frac{(\\beta + \\sum X_i)^{\\alpha+n}}{\\Gamma(\\alpha+n)} \\lambda^{\\alpha+n-1} e^{-\\lambda(\\beta + \\sum X_i)} d\\lambda$$\n",
    "\n",
    "$$= \\frac{(\\beta + \\sum X_i)^{\\alpha+n}}{\\Gamma(\\alpha+n)} \\int_0^{\\infty} \\lambda^{\\alpha+n} e^{-\\lambda(x_{n+1} + \\beta + \\sum X_i)} d\\lambda$$\n",
    "\n",
    "Используя формулу для гамма-интеграла:\n",
    "$$= \\frac{(\\beta + \\sum X_i)^{\\alpha+n}}{\\Gamma(\\alpha+n)} \\cdot \\frac{\\Gamma(\\alpha+n+1)}{(x_{n+1} + \\beta + \\sum X_i)^{\\alpha+n+1}}$$\n",
    "\n",
    "$$= \\frac{(\\alpha+n)(\\beta + \\sum X_i)^{\\alpha+n}}{(x_{n+1} + \\beta + \\sum X_i)^{\\alpha+n+1}}$$\n",
    "\n",
    "Это распределение Ломакса (Lomax distribution) или обобщенное распределение Парето II типа.\n",
    "\n",
    "При $x_{n+1} \\geq 0$:\n",
    "$$f(x_{n+1}|X) = \\frac{(\\alpha+n)(\\beta + \\sum X_i)^{\\alpha+n}}{(x_{n+1} + \\beta + \\sum X_i)^{\\alpha+n+1}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WBXJuchMhzE"
   },
   "source": [
    "# Задача 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYWArd6bMjkD"
   },
   "source": [
    "**Мультиномиальное распределение**\n",
    "\n",
    "Пусть проводится серия из $n$ испытаний и в результате каждого испытания происходит ровно одно событие из набора $A_1, A_2, \\dots, A_m$, причем вероятности этих событий равны соответственно $\\mathsf{p}_1, \\mathsf{p}_2, \\dots, \\mathsf{p}_m$, причем\n",
    "$$\\sum_{i=1}^{m}\\mathsf{p}_i = 1.$$\n",
    "\n",
    "Тогда совместное распределение величин $X_1, X_2, \\dots, X_m$, где $X_k$ — число наступлений события $A_k$ в серии из $n$ испытаний, задается вероятностями\n",
    "\n",
    "$$\n",
    "\\mathsf{P}\\left(X_1 = n_1, \\dots, X_m = n_m, \\right) = \\frac{n!}{n_1!\\dots n_m!}\\mathsf{p}_1^{n_1}\\dots \\mathsf{p}_m^{n_m},\n",
    "$$\n",
    "\n",
    "где $n_1, n_2, \\dots, n_m$ — произвольный набор целых неотрицательных чисел, таких что\n",
    "\n",
    "$$\\sum_{i=1}^m n_i = n.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение задачи 2\n",
    "\n",
    "### 1. Апостериорное распределение\n",
    "\n",
    "**Правдоподобие мультиномиального распределения:**\n",
    "$$P(X_1 = n_1, \\ldots, X_m = n_m | \\mathbf{p}) = \\frac{n!}{n_1! \\cdots n_m!} p_1^{n_1} \\cdots p_m^{n_m}$$\n",
    "\n",
    "где $\\mathbf{p} = (p_1, \\ldots, p_m)$ — вектор вероятностей, $\\sum_{i=1}^m p_i = 1$, и $\\sum_{i=1}^m n_i = n$.\n",
    "\n",
    "**Сопряженное априорное распределение: Распределение Дирихле**\n",
    "\n",
    "Априорное распределение для вектора вероятностей $\\mathbf{p}$:\n",
    "$$\\pi(\\mathbf{p}) = \\frac{\\Gamma(\\sum_{i=1}^m \\alpha_i)}{\\prod_{i=1}^m \\Gamma(\\alpha_i)} \\prod_{i=1}^m p_i^{\\alpha_i - 1}$$\n",
    "\n",
    "где $\\alpha_i > 0$ для всех $i$ — параметры распределения Дирихле, обозначается как $\\mathbf{p} \\sim \\text{Dirichlet}(\\boldsymbol{\\alpha})$ с $\\boldsymbol{\\alpha} = (\\alpha_1, \\ldots, \\alpha_m)$.\n",
    "\n",
    "**Апостериорное распределение:**\n",
    "\n",
    "По формуле Байеса:\n",
    "$$\\pi(\\mathbf{p}|X) \\propto P(X|\\mathbf{p}) \\cdot \\pi(\\mathbf{p})$$\n",
    "\n",
    "$$\\pi(\\mathbf{p}|X) \\propto \\left(\\prod_{i=1}^m p_i^{n_i}\\right) \\cdot \\left(\\prod_{i=1}^m p_i^{\\alpha_i - 1}\\right) = \\prod_{i=1}^m p_i^{n_i + \\alpha_i - 1}$$\n",
    "\n",
    "Это снова форма распределения Дирихле! Следовательно:\n",
    "$$\\mathbf{p}|X \\sim \\text{Dirichlet}(\\boldsymbol{\\alpha} + \\mathbf{n})$$\n",
    "\n",
    "где $\\mathbf{n} = (n_1, \\ldots, n_m)$ — вектор наблюдений.\n",
    "\n",
    "Нормализованная форма:\n",
    "$$\\pi(\\mathbf{p}|X) = \\frac{\\Gamma(\\sum_{i=1}^m (\\alpha_i + n_i))}{\\prod_{i=1}^m \\Gamma(\\alpha_i + n_i)} \\prod_{i=1}^m p_i^{\\alpha_i + n_i - 1}$$\n",
    "\n",
    "**Интерпретация:**\n",
    "- Апостериорные параметры: $\\alpha_i^{post} = \\alpha_i + n_i$\n",
    "- Каждый параметр увеличивается на количество наблюдений соответствующей категории\n",
    "- Априорные параметры $\\alpha_i$ можно интерпретировать как \"псевдонаблюдения\"\n",
    "\n",
    "### 2. Предсказательное распределение\n",
    "\n",
    "Предсказательное распределение для нового наблюдения $X_{new} = (X_{new,1}, \\ldots, X_{new,m})$ при условии, что $\\sum_{i=1}^m X_{new,i} = 1$ (одно испытание):\n",
    "\n",
    "$$P(X_{new}|\\mathbf{X}) = \\int P(X_{new}|\\mathbf{p}) \\pi(\\mathbf{p}|\\mathbf{X}) d\\mathbf{p}$$\n",
    "\n",
    "Для одного испытания (мультиномиальное с $n=1$):\n",
    "$$P(X_{new,i} = 1, X_{new,j} = 0 \\text{ для } j \\neq i | \\mathbf{p}) = p_i$$\n",
    "\n",
    "Предсказательная вероятность:\n",
    "$$P(X_{new,i} = 1 | \\mathbf{X}) = \\int p_i \\cdot \\pi(\\mathbf{p}|\\mathbf{X}) d\\mathbf{p} = E[p_i|\\mathbf{X}]$$\n",
    "\n",
    "Для распределения Дирихле математическое ожидание:\n",
    "$$E[p_i|\\mathbf{X}] = \\frac{\\alpha_i + n_i}{\\sum_{j=1}^m (\\alpha_j + n_j)} = \\frac{\\alpha_i + n_i}{\\sum_{j=1}^m \\alpha_j + n}$$\n",
    "\n",
    "**Для $k$ независимых испытаний:**\n",
    "\n",
    "Предсказательное распределение для $k$ новых испытаний:\n",
    "$$P(X_{new,1} = k_1, \\ldots, X_{new,m} = k_m | \\mathbf{X}) = \\frac{\\Gamma(\\sum_{j=1}^m (\\alpha_j + n_j))}{\\Gamma(\\sum_{j=1}^m (\\alpha_j + n_j) + k)} \\prod_{i=1}^m \\frac{\\Gamma(\\alpha_i + n_i + k_i)}{\\Gamma(\\alpha_i + n_i)} \\cdot \\frac{k!}{k_1! \\cdots k_m!}$$\n",
    "\n",
    "где $\\sum_{i=1}^m k_i = k$.\n",
    "\n",
    "Это **Дирихле-мультиномиальное распределение** (Dirichlet-multinomial distribution).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOvNMoSHMrWR"
   },
   "source": [
    "Произведите байесовский вывод для мультиномиального распределения: найдите апостериорное распределение, используя в качестве сопоряженного распределения к правдоподобию [распределение Дирихле](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D0%94%D0%B8%D1%80%D0%B8%D1%85%D0%BB%D0%B5), найдите предсказательное распределение. Объясните результат."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
